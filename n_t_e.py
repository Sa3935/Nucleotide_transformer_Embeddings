# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mh26T8NBsOUcAGBhYmX7CLLMe37eRs4L
"""

!pip install torch transformers

# Install necessary libraries
!pip install transformers datasets numpy pandas faiss-cpu umap-learn scikit-learn matplotlib sacremoses

# Import necessary modules
import os
import numpy as np
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
import umap
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import torch
import gc
from tqdm import tqdm
import seaborn as sns

# Step 1: Authentication and Model Setup
"""
Using the Nucleotide Transformer 500M multi-species model with custom loading logic.
"""
# Replace with your Hugging Face token
TOKEN = "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"  # Replace this with your actual token
MODEL_NAME = "InstaDeepAI/nucleotide-transformer-v2-500m-multi-species"

# Use trust_remote_code=True to load the custom model
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_auth_token=TOKEN, trust_remote_code=True)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, use_auth_token=TOKEN, trust_remote_code=True)

# Set model to evaluation mode
model.eval()

# Force CPU use
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device).half()  # Convert model to 16-bit precision

# Step 2: Dataset Handling
FASTA_FILE_TRAIN = "/content/train.fasta"
FASTA_FILE_TEST = "/content/test.fasta"
FASTA_FILE_TAXA = "/content/taxa_out.fasta"
FASTA_FILE_GENE = "/content/gene_out.fasta"
METADATA_FILE = "/content/metadata.csv"

def parse_fasta(file_path):
    sequences = []
    labels = []
    current_seq = []
    current_label = None
    with open(file_path, "r") as f:
        for line in f:
            line = line.strip()
            if line.startswith(">"):
                if current_label is not None and current_seq:
                    sequences.append("".join(current_seq))
                    current_seq = []
                parts = line.split("|")
                current_label = parts[2] if len(parts) > 2 else "unknown"
                labels.append(current_label)
            else:
                current_seq.append(line)
        if current_label is not None and current_seq:
            sequences.append("".join(current_seq))
    return sequences, labels

# Generate embeddings for a dataset
def process_dataset(fasta_file, embedding_file, label_file):
    print(f"Processing dataset: {fasta_file}")
    sequences, labels = parse_fasta(fasta_file)
    print("Parsed:", len(sequences), len(labels))

    # Convert labels to numeric
    label_map = {label: idx for idx, label in enumerate(set(labels))}
    numeric_labels = [label_map[l] for l in labels]

    def clear_cache():
        gc.collect()

    def generate_embeddings(sequences, tokenizer, model, initial_batch_size=64, max_batch_size=512):
        embeddings = []
        batch_size = initial_batch_size
        i = 0
        num_sequences = len(sequences)

        with tqdm(total=num_sequences, desc="Embedding Sequences") as pbar:
            while i < num_sequences:
                batch = sequences[i:i+batch_size]
                try:
                    # Limit the sequence length to 500 base pairs
                    inputs = tokenizer(batch, return_tensors="pt", padding=True, truncation=True, max_length=500)
                    inputs = {k: (v.to(device).half() if v.dtype == torch.float else v.to(device)) for k, v in inputs.items()}

                    with torch.no_grad():
                        outputs = model(**inputs, output_hidden_states=True)
                        last_hidden_state = outputs.hidden_states[-1]
                        batch_embeddings = last_hidden_state.mean(dim=1).cpu().numpy()

                    embeddings.extend(batch_embeddings)
                    i += batch_size
                    pbar.update(len(batch))  # progress bar

                    # Increase batch size if possible
                    if batch_size < max_batch_size:
                        batch_size = min(batch_size * 2, max_batch_size)

                except RuntimeError as e:
                    if "out of memory" in str(e):
                        clear_cache()
                        print(f"Out of memory at batch size {batch_size}. Reducing batch size.")
                        batch_size = max(1, batch_size // 2)
                        if batch_size == 1:
                            raise RuntimeError("Batch size too small to process even a single input.")
                    else:
                        raise e

        return np.array(embeddings)

    print("Generating embeddings... This may take a while.")
    embeddings = generate_embeddings(sequences, tokenizer, model)

    # Save embeddings and labels locally
    np.save(embedding_file, embeddings)
    np.save(label_file, numeric_labels)
    print(f"Embeddings and labels for {fasta_file} saved successfully at {embedding_file} and {label_file}.")

    return embeddings, numeric_labels, label_map

# Step 3: Generate and Save Train Embeddings
train_embeddings, train_labels, train_label_map = process_dataset(
    FASTA_FILE_TRAIN, "/content/train_embeddings.npy", "/content/train_labels.npy")

# Load embeddings for future processing
train_embeddings = np.load("/content/train_embeddings.npy")
train_labels = np.load("/content/train_labels.npy")

# Train KNN Model on Train Embeddings
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(train_embeddings, train_labels)
print("KNN model trained successfully on train.fasta")

# Step 4: Evaluate on Other Datasets
evaluation_datasets = {
    "test": (FASTA_FILE_TEST, "/content/test_embeddings.npy", "/content/test_labels.npy"),
    "taxa_out": (FASTA_FILE_TAXA, "/content/taxa_embeddings.npy", "/content/taxa_labels.npy"),
    "gene_out": (FASTA_FILE_GENE, "/content/gene_embeddings.npy", "/content/gene_labels.npy")
}

for dataset_name, (fasta_file, embedding_file, label_file) in evaluation_datasets.items():
    eval_embeddings, eval_labels, eval_label_map = process_dataset(fasta_file, embedding_file, label_file)

    print(f"Loaded embeddings shape for {dataset_name}:", eval_embeddings.shape)
    print(f"Loaded labels length for {dataset_name}:", len(eval_labels))

    # Load embeddings for evaluation
    eval_embeddings = np.load(embedding_file)
    eval_labels = np.load(label_file)

    # Predict and Evaluate
    y_pred = knn.predict(eval_embeddings)

    # Classification Report
    print(f"Classification Report for {dataset_name}:")
    print(classification_report(eval_labels, y_pred))

    # Confusion Matrix
    conf_matrix = confusion_matrix(eval_labels, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues",
                xticklabels=sorted(eval_label_map.keys(), key=lambda x: eval_label_map[x]),
                yticklabels=sorted(eval_label_map.keys(), key=lambda x: eval_label_map[x]))
    plt.title(f"Confusion Matrix for {dataset_name}")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()

    # UMAP Visualization
    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42, metric="cosine")
    embedding_2d = reducer.fit_transform(eval_embeddings)

    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(
        embedding_2d[:, 0],
        embedding_2d[:, 1],
        c=eval_labels,
        cmap="tab20",
        s=10,
        alpha=0.7
    )
    cbar = plt.colorbar(scatter, ticks=range(len(eval_label_map)), label="Taxonomy")
    cbar.ax.set_yticklabels([label for label in sorted(eval_label_map.keys())])
    plt.title(f"UMAP Visualization for {dataset_name}")
    plt.xlabel("UMAP Dimension 1")
    plt.ylabel("UMAP Dimension 2")
    plt.show()

import umap
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import os

# Paths to embedding files and metadata
embedding_files = {
    "test": "/content/test_embeddings.npy",
    "taxa": "/content/taxa_embeddings.npy",
    "gene": "/content/gene_embeddings.npy"
}
metadata_path = "/content/metadata.csv"  # Updated path to your metadata file
output_base_dir = "/content/output_visualizations"  # Base directory to save individual files

os.makedirs(output_base_dir, exist_ok=True)  # Ensure base output directory exists

# Load metadata
metadata = pd.read_csv(metadata_path)

# Taxonomy levels to visualize
taxonomy_levels = ["h0-gene", "h1-kingdom", "h2-phylum", "h3-class", "h4-order", "h5-family", "h6-genus"]

# Ensure metadata has an index that matches embeddings
if "index" not in metadata.columns:
    metadata.reset_index(inplace=True)  # Reset index to ensure alignment

# Process each embedding file
for name, embedding_path in embedding_files.items():
    print(f"Processing embeddings: {name}")

    # Load embeddings
    embeddings = np.load(embedding_path)

    # Ensure metadata and embeddings are aligned
    if len(metadata) != len(embeddings):
        print(f"Warning: Metadata ({len(metadata)}) and embeddings ({len(embeddings)}) are not aligned.")
        aligned_metadata = metadata.iloc[:len(embeddings)]  # Truncate metadata to match embeddings
    else:
        aligned_metadata = metadata

    # Generate UMAP for each taxonomy level
    for taxonomy in taxonomy_levels:
        if taxonomy not in aligned_metadata.columns:
            print(f"Warning: {taxonomy} not found in metadata. Skipping...")
            continue

        print(f"Generating UMAP for {taxonomy} (Embeddings: {name})...")

        # Filter valid labels and embeddings
        valid_indices = aligned_metadata[taxonomy].notnull()  # Ensure no NaNs in labels
        filtered_embeddings = embeddings[valid_indices.to_numpy()]
        filtered_labels = aligned_metadata.loc[valid_indices, taxonomy]

        # Generate UMAP projections
        reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42, metric="cosine")
        embedding_2d = reducer.fit_transform(filtered_embeddings)

        # Create a scatter plot
        plt.figure(figsize=(12, 10))
        scatter = plt.scatter(
            embedding_2d[:, 0],
            embedding_2d[:, 1],
            c=pd.factorize(filtered_labels)[0],  # Convert labels to numeric codes
            cmap="tab20",  # Use a categorical colormap
            s=10,
            alpha=0.7
        )
        cbar = plt.colorbar(scatter, ticks=range(len(filtered_labels.unique())), label=taxonomy)
        cbar.ax.set_yticklabels(filtered_labels.unique())

        plt.title(f"UMAP Visualization for {taxonomy} (Embeddings: {name})")
        plt.xlabel("UMAP Dimension 1")
        plt.ylabel("UMAP Dimension 2")

        # Save the figure in the file-specific subdirectory
        output_dir = os.path.join(output_base_dir, name)
        os.makedirs(output_dir, exist_ok=True)
        output_file = os.path.join(output_dir, f"{taxonomy}.png")
        plt.savefig(output_file, bbox_inches="tight")
        print(f"Saved UMAP visualization for {taxonomy} (Embeddings: {name}) to {output_file}")

        plt.show()